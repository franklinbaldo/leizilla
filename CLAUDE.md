# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Leizilla is a legal document indexing system that crawls, processes, and distributes Brazilian laws as open datasets. It's a sister project to CausaGanha, focused exclusively on indexing all Brazilian laws starting with Rondônia state. The project operates with minimal infrastructure, radical transparency, and a 100% static architecture - no servers or backends to maintain.

## Development Setup

This project uses **uv** for dependency management and follows modern Python packaging standards:

```bash
# Install uv first: curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows
uv sync --dev

# Setup pre-commit hooks and complete environment
just setup
```

## Development Commands

The project uses `just` as a task runner for all development operations:

```bash
# Essential commands
just setup          # Complete development environment setup
just check          # Run all pre-commit checks (lint, format-check, typecheck, test)
just ci             # Comprehensive CI check (what GitHub Actions runs)
just fix            # Apply automatic fixes (ruff + formatting)

# Individual operations
just lint           # Lint with ruff
just format         # Format with ruff
just typecheck      # Type checking with mypy
just test           # Run pytest
just clean          # Clean build artifacts and caches

# Single test execution
uv run pytest tests/test_specific.py -v
```

## Core Architecture

### Internet Archive as Central Pillar

The project's architecture is built around Internet Archive as the foundational component, validated by the CausaGanha project which successfully processed 21+ years of judicial decisions. This approach provides:

- **Free OCR**: Automatic text extraction from uploaded PDFs
- **Permanent storage**: Zero-cost hosting with global CDN
- **Automatic torrents**: P2P distribution generated by IA
- **Shared database**: Distributed DuckDB via IA with conflict prevention

### Data Flow Pipeline

1. **Crawler** (Playwright + AnyIO/Trio): Downloads PDFs from official sources (.gov.br)
2. **Internet Archive Upload**: Immediate archival triggers automatic OCR and torrent generation
3. **ETL Processing** (DuckDB): Local processing of OCR text into structured data
4. **Dataset Publication**: Export to Parquet + JSON Lines formats
5. **Distribution**: GitHub Releases, IA mirrors, and P2P torrents
6. **Client-side Search**: DuckDB-WASM enables SQL queries in browser

### Technology Stack

- **Python 3.12**: Core language with strict type checking (mypy)
- **Playwright + AnyIO**: Async web crawling for JavaScript-heavy government sites
- **DuckDB**: Embedded analytical database, exports Parquet natively
- **Internet Archive**: OCR, permanent storage, and torrent distribution
- **uv**: Fast Python package management
- **ruff**: Linting and formatting
- **GitHub Actions**: Complete CI/CD automation

## Project Structure

```
src/leizilla/           # Main source code (currently minimal - pre-MVP phase)
docs/adr/              # Architecture Decision Records
docs/plans/            # Future feature planning documents
docs/DEVELOPMENT.md    # Detailed technical development guide
tests/                 # Test suite (pytest-based)
data/                  # Local data directory (gitignored)
  └─ leizilla.duckdb   # Local DuckDB database (will be created)
```

## Development Status

**Current Phase**: Pre-MVP (tooling selection and POC development)

The project is in early development with infrastructure setup complete but core functionality still being implemented. The codebase currently contains:
- Complete development environment setup
- ADR documenting Internet Archive architectural decision
- Project scaffolding with Python 3.12 + modern tooling

## Data Architecture

### Local DuckDB Database
- **Location**: `data/leizilla.duckdb` (auto-created, gitignored)
- **Purpose**: Local ETL processing and staging
- **Schema**: Will include `leis` table with full-text content, metadata, and search indices
- **Export**: Native Parquet export for distribution

### Planned Data Formats
- **Parquet**: Columnar analytics format (primary)
- **JSON Lines**: Pipeline-compatible streaming format
- **Torrents**: P2P distribution via Internet Archive

## Quality Standards

- **Type Safety**: All functions require type hints, mypy strict checking
- **Code Style**: ruff formatting with 88-character line length
- **Testing**: pytest with coverage requirements
- **Commits**: Conventional Commits format required
- **Documentation**: ADRs for architectural decisions, clear docstrings for public APIs

## Environment Variables

The project will use `.env` file for configuration:
- `IA_ACCESS_KEY` / `IA_SECRET_KEY`: Internet Archive credentials
- `DUCKDB_PATH`: Database location (defaults to `data/leizilla.duckdb`)
- Crawler configuration (delays, retries, timeouts)

## Roadmap Context

- **Q3/2025**: MVP with Rondônia state laws in Parquet/JSONL
- **Q4/2025**: Federal legislation coverage (1988-present)
- **Q1/2026**: Static frontend (HTML/JS) with DuckDB-WASM search
- **Q2/2026**: Semantic search with embeddings stored in DuckDB

The project emphasizes cost-zero operation, radical transparency, and distributed resilience over traditional cloud-based approaches.